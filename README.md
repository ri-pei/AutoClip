# 自动视频剪辑溯源工具 (Automated Video Clip Finder)

本项目是一个自动化的视频处理流水线，旨在解决一个常见的视频剪辑问题：**当您有一个已经剪辑好的视频片段时，如何从大量的原始、未剪辑的视频素材中，快速、准确地找回所有用到的原始片段及其精确的时间码？**

这个工具链通过一系列智能分析步骤，最终生成一个标准的 `.fcpxml` 文件。您可以将此文件直接导入到 **DaVinci Resolve (达芬奇)** 或 **Final Cut Pro** 等专业视频剪辑软件中，它会自动在时间线上用原始素材重新构建出您的剪辑。

## 核心功能

- **几何变换检测**：自动计算源素材相对于剪辑成品的裁切、缩放和位移。
- **感知哈希匹配**：使用`pHash`图像指纹技术，即使在源素材和成品有颜色差异、压缩伪影或微小扰动的情况下，也能准确匹配帧。
- **高效粗匹配**：利用`BallTree`数据结构，在数万甚至数十万帧的源素材中快速找到每个成品帧的最佳候选匹配。
- **智能片段精炼**：通过分析时间戳偏移量和前瞻性检查，将离散的帧匹配凝聚成连续、稳定的视频片段，有效抵抗匹配抖动和误匹配。
- **标准化输出**：生成行业标准的 FCPXML v1.9 文件，与主流非编软件（NLE）无缝对接。

## 工作流程

整个工具链分为五个核心步骤，由 `main.py` 自动依次执行：

1.  **Step 1: 帧提取与预处理**
    - 从所有源视频和剪辑成品中提取每一帧。
    - 根据参考帧计算几何变换（裁切/缩放）。
    - 对源视频帧应用变换，使其在尺寸和构图上与成品帧对齐。
    - （可选）应用颜色校正LUT和遮罩。

2.  **Step 2: pHash计算**
    - 为第一步中提取的所有对齐后的帧计算`pHash`（感知哈希值）。
    - 将哈希值与帧信息（文件名、时间戳等）一同存入CSV文件，以备后续分析。

3.  **Step 3: 粗略匹配**
    - 加载所有源素材帧的pHash，并构建一个`BallTree`用于快速近邻搜索。
    - 遍历剪辑成品的每一帧，在BallTree中查询汉明距离最近的N个候选匹配帧。
    - 将这些粗略的匹配结果保存到CSV文件中。

4.  **Step 4: 片段精炼**
    - 分析粗匹配结果，识别出在时间上连续的“初步片段”。
    - 对每个初步片段，计算该片段中每一帧的时间偏移量中位数，作为该片段的时间偏移量。
    - 使用此偏移量，在完整的原始帧数据中为每个编辑帧重新寻找最接近的匹配，从而精炼匹配结果。
    - 将精炼后的、连续的帧匹配合并成最终的视频片段，并输出为CSV。

5.  **Step 5: FCPXML生成**
    - 读取最终的片段CSV文件。
    - 根据视频元数据（分辨率、帧率）和片段信息，构建一个符合FCPXML格式的XML文件。
    - 尝试过使用opentimelineio库导出AAF、EDL和Adobe PR XML格式，均失败。
    - 最终选择手动构建FCPXML格式剪辑文件。

## 使用指南

### 1. 环境准备

**依赖软件:**

- **Python 3.8+**
- **FFmpeg & FFprobe**: 这是本项目的核心依赖，必须安装并将其添加到系统的 `PATH` 环境变量中。
  - 访问 [FFmpeg官网](https://ffmpeg.org/download.html) 下载。
  - **验证安装**: 在终端或命令提示符中运行 `ffmpeg -version` 和 `ffprobe -version`，如果能显示版本信息则表示安装成功。

**安装Python库:**

克隆或下载本项目后，在项目根目录下打开终端，运行以下命令安装所有Python依赖：
```bash
pip install -r requirements.txt
```

### 2. 文件和目录结构

大部份文件名和文件夹名可以在config.py中自定义。
在运行前，请按照文件夹组织您的文件。一个典型的例子如下：

```
/your_project_folder/       <-- 项目根目录
|
|-- source/                   <-- [必需] 存放所有原始、未剪辑的视频文件
|   |-- original_video1.mp4
|   |-- original_video2.mov
|   `-- folder_A/
|       `-- original_video3.mp4
|
|-- my_edited_clip.mp4        <-- [必需] 你的剪辑成品视频
|
|-- ref_original.png          <-- [可选] 用于变换计算的参考帧（来自源素材）
|-- ref_edited.png            <-- [可选] 用于变换计算的参考帧（来自剪辑成品）
|
|-- main.py                   <-- 主执行文件
|-- config.py                 <-- 核心配置文件
|-- common.py
|-- step1.py
|-- step2.py
|-- step3.py
|-- step4.py
|-- step5.py
|-- requirements.txt
|
`-- output/                   <-- (此目录会自动创建)
```

### 3. 准备参考帧

这是非常关键的一步！ `ref_original.png` 和 `ref_edited.png` 必须是**来自同一时间点的同一帧画面**。

- **`ref_original.png`**: 从某个**原始视频**中截取一帧。
- **`ref_edited.png`**: 从**剪辑成品**中截取**完全相同**的一帧。

例如，如果你的成品中有一个人物抬手的画面，你需要：
1. 在原始视频中找到这个人物抬手的精确画面，并截图保存为 `ref_original.png`。
2. 在剪辑成品中找到完全相同的画面，截图保存为 `ref_edited.png`。

这些图像将用于计算源素材被如何裁切、缩放以适应成品画面的。

### 4. 配置 `config.py`

打开 `config.py` 文件，根据你的项目情况修改以下参数：

- `WORKING_DIR`: 工作目录，通常保持为 `"."` 即可。
- `EDITED_VIDEO_FILENAME`: 你的剪辑成品文件名，例如 `"my_edited_clip.mp4"`。
- `OUTPUT_DIR`: 所有中间文件和最终结果的输出目录，默认为 `"output"`。
- `SOURCE_VIDEO_FOLDER`: 存放所有源素材的文件夹，默认为 `"source"`。
- `MASK_RECT`: 如果成品视频中有不希望参与匹配的区域（如固定的水印、logo），可以设置一个矩形遮罩 `(x, y, w, h)` 将其涂黑。如果不需要，则设为 `None`。
- `REF_ORIGINAL_FRAME_PATH` / `REF_EDITED_FRAME_PATH`: 参考帧的文件名。
- `IF_RECONSTRUCTED_VIDEO`: （Step 3）是否生成一个粗匹配的对比视频，方便调试。推荐 `True`。
- `IF_STITCHED_IMAGES`: （Step 3）是否生成上下拼接的对比图。速度较慢，仅用于深度调试。
- `FRAME_RATE_FLOAT`: （Step 5）最终时间线的帧率。请确保这与你的剪辑成品视频的帧率一致！例如 `23.976`, `25`, `29.97`。
- `FCPXML_PROJECT_NAME` / `FCPXML_EVENT_NAME`: （Step 5）在剪辑软件中导入后，项目和事件的名称。

### 5. 运行

一切准备就绪后，在项目根目录的终端中运行主程序：

```bash
python main.py
```

程序会依次执行所有步骤，并打印详细的进度信息。根据你的视频数量和长度，整个过程可能需要几分钟到几小时不等。

### 6. 导入到剪辑软件 (Importing into Your NLE)

执行成功后，所有成果都位于 `output` 文件夹中。核心成果是根据 `config.py` 中 `FCPXML_PROJECT_NAME` 命名的 `.fcpxml` 文件。

由于不同剪辑软件对 FCPXML 格式的兼容性差异，我们推荐以下工作流，以获得在 **Adobe Premiere Pro** 中的最佳效果。此流程将 DaVinci Resolve 作为一个高效的格式转换工具。

---

#### **第一步：在 DaVinci Resolve 中进行格式转换**

1.  **新建项目**：打开 DaVinci Resolve 并创建一个新项目。

2.  **导入时间线**：在顶部菜单栏中，选择 `文件(File)` -> `导入(Import)` -> `时间线(Timeline)`。

3.  **选择文件**：在弹出的窗口中，找到并选择我们项目生成的 `.fcpxml` 文件进行导入。

    > **⚠️ 重要提示：关于时间码偏移**
    > 导入后，您可能会发现 Resolve 时间线上的片段时间码与原始视频不完全对应（存在整体偏移）。**这是已知现象，请无需理会。** 我们的目标是利用 Resolve 强大的格式转换能力，而不是在此进行剪辑。片段的**顺序和时长是正确的**，这才是关键。

4.  **导出时间线**：导入成功后，立即进行导出。再次点击菜单栏 `文件(File)` -> `导出(Export)` -> `时间线(Timeline)`。

5.  **选择导出格式**：在导出设置窗口中，将 **格式（Format）** 选择为 **`FCP 7 XML V5 (*.xml)`**。这是与 Premiere Pro 兼容性最好的格式。将这个新的 `.xml` 文件保存到您的项目中。

---

#### **第二步：在 Adobe Premiere Pro 中导入并开始创作**

1.  **新建项目**：在 Premiere Pro 中新建一个项目。

2.  **导入XML文件**：点击 `文件(File)` -> `导入(Import)`，选择上一步从 DaVinci Resolve 中导出的 `.xml` 文件。

3.  **打开序列**：导入后，您会在项目面板（通常在左下角）看到一个新的序列（Sequence）。双击打开它。

此时，您的剪辑成品已经被精确地用原始素材在 Premiere Pro 的时间线上重建了！

现在，您可以开始进行精修，例如：
- 微调个别识别不准确的剪辑点。
- 重新添加算法无法识别的转场特效（如渐隐渐现、叠化等）。
- 进行最终的调色和音频处理。

---

#### **成果展示 (Showcase)**

使用本工具流完成的视频项目示例，欢迎观看：
- **【Hi-Res·4K原生非AI·UHD高码率复刻】森口博子「BEYOND THE TIME」官方动画MV【中日双语歌词】《机动战士高达 逆袭的夏亚》主题曲(https://www.bilibili.com/video/BV1uaj5z1Eue/)**

## 许可证

本项目采用 [MIT许可证](LICENSE)。

## 使用的大模型提示词展示

Code is cheap, show me the talk

1.  **Step 1: 帧提取与预处理**
有个任务需求如下，要在本地用Python完成。请通盘考虑所有需求后，先告诉我第一步如何完成工作文件夹下所有视频的帧提取和命名工作。

⸻

🎯 任务描述：

我有一个剪辑后的视频，是从多个原始素材视频中剪辑拼接而成的。我需要使用Python编写代码，自动识别剪辑视频中的每一段对应于原始素材中的哪一段，包括其在原始素材中的起始和结束时间（精确到帧级，即毫秒级时间戳）。最终输出一个和剪辑视频**画面内容完全一致（不考虑水印、硬字幕或分辨率差异）**的新视频，拼接自原始素材的各段。音频不考虑，处理仅限于视频画面。

⸻

📁 输入数据情况：
•	原始素材：多个视频文件，可能是 HDR10 编码，统一放在一个文件夹下，此文件夹即工作目录。
•	剪辑后视频：1 个 视频文件，有水印或硬字幕，分辨率可能不同于原始素材。放在和原始素材同一个目录，即工作目录下。后续生成的文件都放在此目录下的output文件夹下。
•	音轨完全不同，不可用作对齐依据。
•	假设剪辑后视频不会在原始素材片段上添加转场和渐变，所有剪辑片段是直接切割自原视频。

⸻

⚙️ 处理流程建议

请按以下顺序分步骤实现逻辑，每步都考虑缓存/跳过重复计算：

使用 ffmpeg 提取所有视频帧为图像文件（jpg/png）：剪辑视频与原始视频都要提取，各自保存在使用视频文件文件名（不含拓展名）的独立子目录中（不会存在文件名只有拓展名不同的原视频）。提取后的帧截图中分别放在视频文件同名子目录中，要包含时间戳和帧编号，便于索引与对齐。由于有水印或硬字幕，且分辨率可能不同于原始素材，需要先调整每张原始视频提取截图分辨率和剪辑视频一致，并设置一个矩形的遮罩区域盖住水印或硬字幕区域。请注意，遮罩区域即涂黑在输出原始视频帧截图中也要进行。后续帧匹配等操作使用这些图片文件进行，无需打开视频文件。

使用python为每个视频的每一帧计算感知哈希值（pHash）并缓存到csv表格：表格中的一行对应一帧，分别是视频名、图片文件名、帧数、精确时间、感知哈希值和图片相对工作目录路径，行与行之间不要留空白行。支持跳过已存在且匹配对应视频的缓存表格（验证每个视频文件名和各自总帧数是否对应即可，不同视频但帧数相同的概率相当小）。

执行帧粗略匹配，为剪辑视频的每一帧找出原始视频中最接近的帧的候选。使用哈希距离（汉明距离）快速初筛（pHash Hamming 距离）；由于原始素材可能很大，需要优化匹配算法，考虑先采用排序方法找到最接近的top N帧。输出结果是csv表格，依次列出剪辑后视频的每一帧、每一时间点，哈希值和对应少数最相似候选帧、出处视频、图片路径、帧号、时间点、哈希距离的列表。为了检查这一步结果，请把剪辑帧图片和对应原视频最相似的候选帧的图片上下拼接后，输出在output文件夹下的coarse_match文件夹下，命名方式按照剪辑帧图片命名。

执行精确匹配。仅对top N候选帧的前后，用特征点匹配（如 ORB/SIFT + RANSAC）或 SSIM 做进一步细化，顺次计算差异直到差异开始增加即停止，从这些中选出差异最小的帧。匹配结果同样写入帧匹配表格，同样把剪辑帧图片和对应原视频最相似的候选帧的图片上下拼接后，输出在output文件夹下的fine_match文件夹下，命名方式按照剪辑帧图片命名。

分段识别与还原拼接：若连续的剪辑帧匹配到原始帧也是连续的，可认为这一段剪辑来自原素材中某一段。输出一个 .csv 表格，记录剪辑视频每个段的起止时间及其原视频中对应的起止时间。之后可用 ffmpeg 按该表格拼接出与剪辑视频内容一致、但画质更高、无水印的新视频。
⸻

2.  **Step 2: pHash计算**
我有个任务需求如下，要在本地用Python完成。目前第一步已完成，请参照具体实现详述部份。请通盘考虑后续需求后，为第2步编写代码。

⸻

🎯 任务描述：

我有一个剪辑后的视频，是从多个原始素材视频中剪辑拼接而成的。我需要使用Python编写代码，自动识别剪辑视频中的每一段对应于原始素材中的哪一段，包括其在原始素材中的起始和结束时间（精确到帧级，即毫秒级时间戳）。最终输出一个和剪辑视频**画面内容完全一致（不考虑水印、硬字幕或分辨率差异）**的新视频，拼接自原始素材的各段。音频不考虑，处理仅限于视频画面。

⸻

📁 输入数据情况：
•	原始素材：多个视频文件，可能是 HDR10 编码，统一放在一个文件夹下，此文件夹即工作目录。
•	剪辑后视频：1 个 视频文件，有水印或硬字幕，分辨率可能不同于原始素材。放在和原始素材同一个目录，即工作目录下。后续生成的文件都放在此目录下的output文件夹下。
•	音轨完全不同，不可用作对齐依据。
•	假设剪辑后视频不会在原始素材片段上添加转场和渐变，所有剪辑片段是直接切割自原视频。

⸻
⚙️ 处理流程设想

请按以下顺序分步骤实现逻辑，每步都考虑缓存/跳过重复计算：

使用 ffmpeg 提取所有视频帧为图像文件（png）：剪辑视频与原始视频都要提取，各自保存在使用视频文件文件名（不含拓展名）的独立子目录中（不会存在文件名只有拓展名不同的原视频）。提取后的帧截图中分别放在视频文件同名子目录中，要包含时间戳和帧编号，便于索引与对齐。由于有水印或硬字幕，且分辨率可能不同于原始素材，需要先调整每张原始视频提取截图分辨率和剪辑视频一致，并设置一个矩形的遮罩区域盖住水印或硬字幕区域。请注意，遮罩区域即涂黑在输出原始视频帧截图中也要进行。后续帧匹配等操作使用这些图片文件进行，无需打开视频文件。

使用python为每个视频的每一帧计算感知哈希值（pHash）并缓存到csv表格：表格中的一行对应一帧，分别是视频名、图片文件名、帧数、精确时间、感知哈希值和图片相对工作目录路径，行与行之间不要留空白行。支持跳过已存在且匹配对应视频的缓存表格（验证每个视频文件名和各自总帧数是否对应即可，不同视频但帧数相同的概率相当小）。

执行帧粗略匹配，为剪辑视频的每一帧找出原始视频中最接近的帧的候选。使用哈希距离（汉明距离）快速初筛（pHash Hamming 距离）；由于原始素材可能很大，需要优化匹配算法，考虑先采用排序方法找到最接近的top N帧。输出结果是csv表格，依次列出剪辑后视频的每一帧、每一时间点，哈希值和对应少数最相似候选帧、出处视频、图片路径、帧号、时间点、哈希距离的列表。为了检查这一步结果，请把剪辑帧图片和对应原视频最相似的候选帧的图片上下拼接后，输出在output文件夹下的coarse_match文件夹下，命名方式按照剪辑帧图片命名。

执行精确匹配。仅对top N候选帧的前后，用特征点匹配（如 ORB/SIFT + RANSAC）或 SSIM 做进一步细化，顺次计算差异直到差异开始增加即停止，从这些中选出差异最小的帧。匹配结果同样写入帧匹配表格，同样把剪辑帧图片和对应原视频最相似的候选帧的图片上下拼接后，输出在output文件夹下的fine_match文件夹下，命名方式按照剪辑帧图片命名。

分段识别与还原拼接：若连续的剪辑帧匹配到原始帧也是连续的，可认为这一段剪辑来自原素材中某一段。输出一个 .csv 表格，记录剪辑视频每个段的起止时间及其原视频中对应的起止时间。之后可用 ffmpeg 按该表格拼接出与剪辑视频内容一致、但画质更高、无水印的新视频。
⸻

具体实现详述

第一步：提取所有视频的帧并进行预处理（调整大小、遮罩）
这一步的目标是：

识别工作目录下的所有视频文件（包括剪辑后的视频和原始素材视频）。

为剪辑后的视频确定其分辨率。

为每个视频（剪辑视频和原始素材）创建一个独立的子文件夹（在 output/<视频文件名无后缀>/frames/ 路径下）来存放提取的帧。

使用 ffmpeg 从每个视频中提取所有帧为 PNG 图片。

为提取的每一帧生成包含**帧号（0开始）和精确时间戳（毫秒级）**的文件名，格式如：<视频文件名无后缀>_frame_0000000_time_HH-MM-SS-mmm.png。

对于从原始素材视频提取的帧：将其分辨率调整为与剪辑后视频的分辨率一致。

对于所有提取的帧（包括剪辑视频的帧和调整大小后的原始素材帧）：在一个用户指定的矩形区域应用黑色遮罩，以覆盖可能存在的水印或硬字幕。

实现缓存机制：如果一个视频的帧已经提取并处理完毕（目标文件夹存在且包含图片），则跳过该视频。

3.  **Step 3: 粗略匹配**
我有个任务需求如下，要在本地用Python完成。目前前2步已完成，请参照具体实现详述部份。目前在工作目录下已经存在第1步得到的所有帧提取的图片，第2步得到了每个视频对应的pHash CSV表格。前两步的代码见附件，请通盘考虑后续需求后，为第3步编写代码。

⸻

🎯 任务描述：

我有一个剪辑后的视频，是从多个原始素材视频中剪辑拼接而成的。我需要使用Python编写代码，自动识别剪辑视频中的每一段对应于原始素材中的哪一段，包括其在原始素材中的起始和结束时间（精确到帧级，即毫秒级时间戳）。最终输出一个和剪辑视频**画面内容完全一致（不考虑水印、硬字幕或分辨率差异）**的新视频，拼接自原始素材的各段。音频不考虑，处理仅限于视频画面。

⸻

📁 输入数据情况：
•	原始素材：多个视频文件，可能是 HDR10 编码，统一放在一个文件夹下，此文件夹即工作目录。
•	剪辑后视频：1 个 视频文件，有水印或硬字幕，分辨率可能不同于原始素材。放在和原始素材同一个目录，即工作目录下。后续生成的文件都放在此目录下的output文件夹下。
•	音轨完全不同，不可用作对齐依据。
•	假设剪辑后视频不会在原始素材片段上添加转场和渐变，所有剪辑片段是直接切割自原视频。

⸻
⚙️ 处理流程设想

请按以下顺序分步骤实现逻辑，每步都考虑缓存/跳过重复计算：

使用 ffmpeg 提取所有视频帧为图像文件（png）：剪辑视频与原始视频都要提取，各自保存在使用视频文件文件名（不含拓展名）的独立子目录中（不会存在文件名只有拓展名不同的原视频）。提取后的帧截图中分别放在视频文件同名子目录中，要包含时间戳和帧编号，便于索引与对齐。由于有水印或硬字幕，且分辨率可能不同于原始素材，需要先调整每张原始视频提取截图分辨率和剪辑视频一致，并设置一个矩形的遮罩区域盖住水印或硬字幕区域。请注意，遮罩区域即涂黑在输出原始视频帧截图中也要进行。后续帧匹配等操作使用这些图片文件进行，无需打开视频文件。

使用python为每个视频的每一帧计算感知哈希值（pHash）并缓存到csv表格：表格中的一行对应一帧，分别是视频名、图片文件名、帧数、精确时间、感知哈希值和图片相对工作目录路径，行与行之间不要留空白行。支持跳过已存在且匹配对应视频的缓存表格（验证每个视频文件名和各自总帧数是否对应即可，不同视频但帧数相同的概率相当小）。

执行帧粗略匹配，为剪辑视频的每一帧找出原始视频中最接近的帧的候选。使用哈希距离（汉明距离）快速初筛（pHash Hamming 距离）；由于原始素材可能很大，需要优化匹配算法，考虑先采用排序方法找到最接近的top N帧。输出结果是csv表格，依次列出剪辑后视频的每一帧、每一时间点，哈希值和对应少数最相似候选帧、出处视频、图片路径、帧号、时间点、哈希距离的列表。为了检查这一步结果，请把剪辑帧图片和对应原视频最相似的候选帧的图片上下拼接后，输出在output文件夹下的coarse_match文件夹下，命名方式按照剪辑帧图片命名。

执行精确匹配。仅对top N候选帧的前后，用特征点匹配（如 ORB/SIFT + RANSAC）或 SSIM 做进一步细化，顺次计算差异直到差异开始增加即停止，从这些中选出差异最小的帧。匹配结果同样写入帧匹配表格，同样把剪辑帧图片和对应原视频最相似的候选帧的图片上下拼接后，输出在output文件夹下的fine_match文件夹下，命名方式按照剪辑帧图片命名。

分段识别与还原拼接：若连续的剪辑帧匹配到原始帧也是连续的，可认为这一段剪辑来自原素材中某一段。输出一个 .csv 表格，记录剪辑视频每个段的起止时间及其原视频中对应的起止时间。之后可用 ffmpeg 按该表格拼接出与剪辑视频内容一致、但画质更高、无水印的新视频。
⸻

具体实现详述

第1步：提取所有视频的帧并进行预处理（调整大小、遮罩）
这一步实现步骤：

识别工作目录下的所有视频文件（包括剪辑后的视频和原始素材视频）。

为剪辑后的视频确定其分辨率。

为每个视频（剪辑视频和原始素材）创建一个独立的子文件夹（在 output/<视频文件名无后缀>/frames/ 路径下）来存放提取的帧。

使用 ffmpeg 从每个视频中提取所有帧为 PNG 图片。

为提取的每一帧生成包含**帧号（0开始）和精确时间戳（毫秒级）**的文件名，格式如：<视频文件名无后缀>_frame_0000000_time_HH-MM-SS-mmm.png。

对于从原始素材视频提取的帧：将其分辨率调整为与剪辑后视频的分辨率一致。

对于所有提取的帧（包括剪辑视频的帧和调整大小后的原始素材帧）：在一个用户指定的矩形区域应用黑色遮罩，以覆盖可能存在的水印或硬字幕。

实现缓存机制：如果一个视频的帧已经提取并处理完毕（目标文件夹存在且包含图片），则跳过该视频。

第2步：为每个视频的每一帧计算感知哈希值（pHash）并缓存到CSV表格
这一步的核心任务是：

遍历 output 文件夹下每个视频的 frames 子目录。

对每张图片，计算其感知哈希值。

将帧信息（视频名、图片文件名、帧号、时间戳（毫秒）、pHash、相对路径）存储到CSV文件中（在output/<视频文件名无后缀>	/<视频文件名无后缀>_phash.csv）

CSV的表头是“video_name, image_filename, frame_number, timestamp_ms, phash, image_path”，image_path是相对于工作目录的路径。

实现缓存机制：如果某个视频的CSV已存在，并且其记录的视频名和总帧数与当前 frames 目录中的情况一致，则跳过该视频的处理。


4.  **Step 4: 片段精炼**

有个任务需求如下，要在本地用Python完成。目前前3步已完成，请参照具体实现详述部份。目前在工作目录下已经存在第1步得到的所有帧提取的图片，第2步得到了每个视频对应的pHash CSV表格，第3步得到的coarse_match表格。我本来想在第3步后加入精确匹配，但是目前第3步结果好于预期：每一段的剪辑整体对应无误；转场都正确，可能转场前后的对应帧有偏离，但是偏的不多，因为粗略看上去没啥问题；每一段中虽然能看出来少量帧匹配的原视频帧不完全一致，但也非常接近并在正确的对应帧附近。

因此我觉得可以跳过精确匹配阶段，直接根据第三步结果确定剪辑视频的每一段对应原视频段落。问题的关键在于匹配算法，请和我探讨以决定匹配算法。我观察到如果按照剪辑视频每帧时间为X轴，其所匹配原视频帧时间为y轴作图，图像是一段一段斜率为1的直线，当然由于匹配问题，每段直线有的点偏离每段整体直线，这个说明匹配错误，更正确的匹配应该在直线上，可以按照这条直线确定匹配帧。如果按照这个思路做匹配，算法如何写？

以下是之前步骤的信息，供参考
⸻

🎯 任务描述：

我有一个剪辑后的视频，是从多个原始素材视频中剪辑拼接而成的。我需要使用Python编写代码，自动识别剪辑视频中的每一段对应于原始素材中的哪一段，包括其在原始素材中的起始和结束时间（精确到帧级，即毫秒级时间戳）。最终输出一个和剪辑视频**画面内容完全一致（不考虑水印、硬字幕或分辨率差异）**的新视频，拼接自原始素材的各段。音频不考虑，处理仅限于视频画面。

⸻

📁 输入数据情况：
•	原始素材：多个视频文件，可能是 HDR10 编码，统一放在一个文件夹下，此文件夹即工作目录。
•	剪辑后视频：1 个 视频文件，有水印或硬字幕，分辨率可能不同于原始素材。放在和原始素材同一个目录，即工作目录下。后续生成的文件都放在此目录下的output文件夹下。
•	音轨完全不同，不可用作对齐依据。
•	假设剪辑后视频不会在原始素材片段上添加转场和渐变，所有剪辑片段是直接切割自原视频。

⸻
⚙️ 处理流程设想

请按以下顺序分步骤实现逻辑，每步都考虑缓存/跳过重复计算：

使用 ffmpeg 提取所有视频帧为图像文件（png）：剪辑视频与原始视频都要提取，各自保存在使用视频文件文件名（不含拓展名）的独立子目录中（不会存在文件名只有拓展名不同的原视频）。提取后的帧截图中分别放在视频文件同名子目录中，要包含时间戳和帧编号，便于索引与对齐。由于有水印或硬字幕，且分辨率可能不同于原始素材，需要先调整每张原始视频提取截图分辨率和剪辑视频一致，并设置一个矩形的遮罩区域盖住水印或硬字幕区域。请注意，遮罩区域即涂黑在输出原始视频帧截图中也要进行。后续帧匹配等操作使用这些图片文件进行，无需打开视频文件。

使用python为每个视频的每一帧计算感知哈希值（pHash）并缓存到csv表格：表格中的一行对应一帧，分别是视频名、图片文件名、帧数、精确时间、感知哈希值和图片相对工作目录路径，行与行之间不要留空白行。支持跳过已存在且匹配对应视频的缓存表格（验证每个视频文件名和各自总帧数是否对应即可，不同视频但帧数相同的概率相当小）。

执行帧粗略匹配，为剪辑视频的每一帧找出原始视频中最接近的帧的候选。使用哈希距离（汉明距离）快速初筛（pHash Hamming 距离）；由于原始素材可能很大，需要优化匹配算法，考虑先采用排序方法找到最接近的top N帧。输出结果是csv表格，依次列出剪辑后视频的每一帧、每一时间点，哈希值和对应少数最相似候选帧、出处视频、图片路径、帧号、时间点、哈希距离的列表。为了检查这一步结果，请把剪辑帧图片和对应原视频最相似的候选帧的图片上下拼接后，输出在output文件夹下的coarse_match文件夹下，命名方式按照剪辑帧图片命名。

执行精确匹配。帧粗略匹配仅生成了topN供精确匹配候选，精细匹配需要选出匹配最接近的原视频画面。首先，对粗略匹配的topN做如下筛选：粗略匹配csv给出了每个topN候选帧的汉明距离，仅保留topN中汉明距离不超过“topN最小pHash距离+10”的帧进行精确匹配。筛选出仅对top N候选帧的前后，用特征点匹配（如 ORB/SIFT + RANSAC）或 SSIM 做进一步细化，顺次计算差异直到差异开始增加即停止（最多不超过前后5帧），从这些中选出差异最小的帧。匹配结果同样写入帧匹配表格，同样把剪辑帧图片和对应原视频最相似的候选帧的图片上下拼接后，输出在output文件夹下的fine_match文件夹下，命名方式按照剪辑帧图片命名。

分段识别与还原拼接：若连续的剪辑帧匹配到原始帧也是连续的，可认为这一段剪辑来自原素材中某一段。输出一个 .csv 表格，记录剪辑视频每个段的起止时间及其原视频中对应的起止时间。之后可用 ffmpeg 按该表格拼接出与剪辑视频内容一致、但画质更高、无水印的新视频。
⸻
前几步生成信息的描述是：

工作目录 (Working Directory):

与步骤1、2、3中 WORKING_DIR 变量所指向的目录相同。脚本将从此目录解析相对路径。

例如：D:/my_video_project 或 . (如果脚本在工作目录中运行)。

基础输出目录 (Base Output Directory):

即步骤1、2、3中 OUTPUT_DIR_NAME (通常是 "output") 指定的目录，位于工作目录下。

路径示例：D:/my_video_project/output/ 或 ./output/。

剪辑后视频的帧图像:

位置：WORKING_DIR/OUTPUT_DIR_NAME/<edited_video_name_no_ext>/frames/

文件名格式：<edited_video_name_no_ext>_frame_xxxxxxx_time_HH-MM-SS-mmm.png

这些图像是步骤1生成的，经过了遮罩处理。步骤4可能需要读取这些图像进行特征点匹配。

剪辑后视频的帧图像对应的pHash值<edited_video_name_no_ext>_phash.csv位于WORKING_DIR/OUTPUT_DIR_NAME/<edited_video_name_no_ext>/中

原始素材视频的帧图像:

位置：WORKING_DIR/OUTPUT_DIR_NAME/<original_video_name_no_ext>/frames/ (每个原始视频一个子目录)

文件名格式：<original_video_name_no_ext>_frame_xxxxxxx_time_HH-MM-SS-mmm.png

这些图像也是步骤1生成的，已经调整到与剪辑视频相同的分辨率并进行了遮罩处理。步骤4将从这些图像中选取候选帧进行精确匹配。

原始素材视频的帧图像对应的pHash值<original_video_name_no_ext>_phash.csv位于WORKING_DIR/OUTPUT_DIR_NAME/<original_video_name_no_ext>/中

粗略匹配结果CSV文件:

文件名：COARSE_MATCH_CSV_FILENAME (在步骤3中定义，默认为 coarse_match_results.csv)。

位置：WORKING_DIR/OUTPUT_DIR_NAME/coarse_match_results.csv

路径示例：D:/my_video_project/output/coarse_match_results.csv

关键内容：这个CSV文件是步骤3的核心输出，步骤4将主要依赖它。每一行代表剪辑视频的一帧，并包含以下重要列：

edited_frame_filename: 剪辑视频的帧文件名。

edited_image_path: 剪辑视频帧图像相对于 WORKING_DIR 的路径。

top_n_matches: 这是一个 JSON字符串，里面是一个列表，列表中的每个元素是一个字典，代表一个粗略匹配上的原始素材候选帧。每个候选帧字典应包含：

original_video_name: 候选帧所属的原始视频文件名（无后缀）。

original_frame_filename: 候选原始帧的文件名。

original_frame_number: 候选原始帧的帧号。

original_timestamp_ms: 候选原始帧的时间戳（毫秒）。

original_phash: 候选原始帧的pHash值。

original_image_path: 候选原始帧图像相对于 WORKING_DIR 的路径。

phash_distance: 该候选帧与对应剪辑帧的pHash汉明距离。
⸻


5.  **Step 5: FCPXML生成**


请你扮演一位专业的 Python 程序员，擅长处理 XML 文件和视频编辑元数据。

我需要你编写一个 Python 脚本，该脚本能够将一个 CSV 文件（final_video_segments_refined.csv）转换为 FCPXML 格式的文件，以便该 FCPXML 文件能够成功导入 DaVinci Resolve 中。

重要约束：
* 脚本不能使用 opentimelineio 库。
* 生成的 FCPXML 文件结构和内容必须严格参考我提供的 fcpxml格式范例.txt 文件。
附件信息：
1. fcpxml格式范例.txt：这是目标 FCPXML 文件的格式和结构范例。请务必仔细分析并遵循此范例。
2. final_video_segments_refined.csv：这是输入 CSV 文件的范例，包含视频剪辑片段的信息。
脚本配置要求：请在 Python 脚本的开头设置以下可配置变量，方便用户修改：
* WORK_DIR：原始视频素材所在的工作目录 (例如："D:/Videos/beyond the time 2/")。
* FRAME_RATE_FLOAT：视频帧率的浮点数值 (例如：23.976)。
* FRAME_DURATION_STR：单帧时长的字符串表示，用于 FCPXML 中的时间值 (例如："1001/24000s")。这个字符串中的分子和分母将用于所有时间计算。
* VIDEO_WIDTH：视频宽度 (例如：1920)。
* VIDEO_HEIGHT：视频高度 (例如：1080)。
FCPXML 转换关键点与逻辑：
1. 时间格式与计算：
    * FCPXML 中所有与时间相关的属性（如 start, duration, offset, tcStart 等）都必须以 "分子/分母s" 的字符串格式表示，例如 "169170001/24000s"。
    * 这里的“分母”必须与用户配置的 FRAME_DURATION_STR 中的分母一致。
    * 这里的“分子”必须是 FRAME_DURATION_STR 中分子的整数倍。
    * 所有时间相关的计算都应基于 CSV 文件中的 _frame 列数据和 FRAME_DURATION_STR 进行，忽略 CSV 文件中的 _time_ms 列数据。1
2. <resources> 部分：
    * 应包含一个或多个 <asset> 元素，对应 CSV 文件 original_video_name 列中出现的不同原始视频素材。
    * 每个 <asset> 的 id 属性应自动生成并保持唯一（例如 r1, r2, ...），并在后续 <asset-clip> 的 ref 属性中被正确引用。
    * 每个 <asset> 的 name 属性应为原始素材的文件名（例如，若 original_video_name 为 "original"，则 name="original.mp4"，假设后缀固定为 .mp4）。
    * 每个 <asset> 的 src 属性应指向原始素材的完整文件路径，格式为 file://localhost/WORK_DIR/原始文件名.mp4。
    * 假设所有原始素材的视频宽度、高度和帧率都一致，因此它们共享同一个 <format> 定义（例如 id="r0"）。这个 <format> 节点的 name (例如 FFVideoFormat1080p2398) 可以是固定的或者基于配置生成，其 width, height, frameDuration 属性应根据脚本开头的配置变量生成。
    * <asset> 的 duration 属性（如范例中的 172832660/24000s）代表原始素材的总时长。如果 CSV 中涉及多个不同的原始素材，脚本需要为每个原始素材生成一个 <asset> 条目。此 duration 值可以基于范例中的值，或者如果无法轻易确定，则使用一个足够大的占位值。
3. <library> 和 <sequence> 部分：
    * <event name> 和 <project name> 可以固定为如范例所示的 "Timeline 1 (Resolve)"，或允许用户配置。
    * <sequence> 的 tcStart 属性值应为 "0/单帧时长分母s" (例如，基于 FRAME_DURATION_STR 计算得出 "0/24000s")。
    * <sequence> 的 duration 属性值：计算公式为 (CSV 文件中最后一行的 'edited_end_frame' + 1) * 单帧时长分子 / 单帧时长分母，无需约分并格式化为字符串。例如，如果最后一行的 edited_end_frame 是 303，FRAME_DURATION_STR 是 "1001/24000s"，则 duration 是 (303 + 1) * 1001，结果为 304304/24000s。
    * <sequence> 的 format 属性应引用 <resources> 中定义的 <format> 的 id (例如 "r0")。
    * <sequence> 的 tcFormat 可以固定为 "NDF"。
4. <spine> 和 <asset-clip> 部分：
    * CSV 文件中的每一行对应 <spine> 内的一个 <asset-clip> 元素。
    * name: 按照剪辑数量顺序命名，例如 clip0001, clip0002, clip0003, ...
    * ref: 引用该剪辑片段对应原始素材在 <resources> 中定义的 <asset> 的 id。
    * offset: 根据当前行 edited_start_frame 计算：edited_start_frame * 单帧时长分子 / 单帧时长分母，并无需约分格式化为字符串。
    * duration: 根据当前行 edited_start_frame 和 edited_end_frame 计算：(edited_end_frame - edited_start_frame + 1) * 单帧时长分子 / 单帧时长分母，并无需约分格式化为字符串。不要使用 original_start_frame 或 original_end_frame 来计算此处的 duration。
    * start: 根据当前行 original_start_frame 计算：original_start_frame * 单帧时长分子 / 单帧时长分母，并格式化为字符串。
    * 其他属性如 tcFormat (NDF), format (e.g., r0), enabled (1), 以及子元素 <adjust-transform> (scale="1 1" anchor="0 0" position="0 0") 可以暂时硬编码为范例中所示的值。
输出要求：
* 脚本应将生成的 FCPXML 内容输出到一个新的 .fcpxml 文件。文件名可以基于输入 CSV 文件名自动生成（例如 final_video_segments_refined_output.fcpxml）或允许用户在运行时指定。
* 请确保 Python 脚本结构清晰、注释良好、易于理解和修改。
请仔细分析提供的范例文件和上述所有转换规则，编写 Python 脚本。